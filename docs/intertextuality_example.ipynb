{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cylleneus + NLP\n",
    "===============\n",
    "\n",
    "Once installed, the Cylleneus engine can be used in conjunction with the CLTK to perform queries programmatically via the search API. In this way, the engine can in fact be used to build NLP applications. One very simple and straightforward use of Cylleneus' lemma-based query functionality would be to try to find 'intertexts' -- passages of text that are lexically similar to, but not morphologically identical to, some source text. Let's try it out.\n",
    "\n",
    "First, set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Some standard CLTK imports\n",
    "from cltk.tokenize.latin.word import WordTokenizer\n",
    "from cltk.stop.latin import STOPS_LIST\n",
    "STOPS_LIST += ['-que', '-ve', '-ne']\n",
    "\n",
    "# We need tell Cylleneus what corpus we want to search, and then instantiate a Searcher object to execute specific queries.\n",
    "from corpus import Corpus\n",
    "from search import Searcher, Collection\n",
    "\n",
    "# Utility imports\n",
    "from copy import copy\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Perseus Digital Library minicorpus that comes pre-installed with the Cylleneus repository; it includes the major works of Vergil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = Corpus('perseus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to abstract away morphological details of our source text, we are also going to need to tokenize and lemmatize this text. In this case, for simplicity's sake, we will just be searching for a single phrase, which we can input manually. Since the text isn't coming from a structured corpus, we can use the built-in plaintext tokenizer and lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# The plaintext tokenizer is suitable for 'raw' Latin text.\n",
    "from corpus.default import CachedTokenizer\n",
    "\n",
    "# The lemma filter takes a sequence of tokens (word-forms) and uses the Latin WordNet for lemmatization and morphological analysis.\n",
    "from engine.analysis.filters import CachedLemmaFilter\n",
    "\n",
    "word_tokenizer = WordTokenizer()\n",
    "tokenizer = CachedTokenizer()\n",
    "lemmatizer = CachedLemmaFilter(cached=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our source text through our lemmatization pipeline. In this fabricated example, we are going to search for texts similar to the phrase of Lucretius: *gelidamque pruinam* (Lucr. *RN.* 2.431)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[",
      "CylleneusToken(positions=True, chars=True, stopped=False, boost=1.0, removestops=True, mode='index', original='gelidam', text='gelidam', pos=0, startchar=0, endchar=7)",
      ",\n ",
      "CylleneusToken(positions=True, chars=True, stopped=False, boost=1.0, removestops=True, mode='index', original='pruinam', text='pruinam', pos=1, startchar=7, endchar=14)",
      "]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "text = 'gelidamque pruinam'\n",
    "\n",
    "# For efficiency the tokenizer reuses a single Token object, so each token needs to be copied to be preserved\n",
    "words = [word for word in word_tokenizer.tokenize(text) if word not in STOPS_LIST]\n",
    "tokens = [copy(token) for token in tokenizer(words, mode='index', tokenize=False)]\n",
    "pprint(tokens)\n",
    "\n",
    "lemmas = []\n",
    "for token in tokens:   \n",
    "    lemmatized = set()\n",
    "    for lemma in lemmatizer([copy(token),]):\n",
    "        lemmatized.add(lemma.text.split(':')[0])\n",
    "    \n",
    "    lemmas.append(list(lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we need to construct a well-formed lemma-based query for Cylleneus to execute. We could simply combine the lemmatized tokens together as a sequence.\n",
    "\n",
    "NB. The lemmatizer tries to be inclusive as possible, so a form like *fatis* will generate multiple lemmas for possible matching: *fatum* as well as *fatis* and *fatus*. This is why, if we were to inspect the `lemmas` object, we would find that each word of the original text resolves to a list of lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[['gelidus', 'gelida'], ['pruina']]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "pprint(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "'\"(<gelidus> OR <gelida>) THEN <pruina>\"'",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Construct sequential lemma-based query\n",
    "subqueries = []\n",
    "for i, lemma in enumerate(lemmas):\n",
    "    # If lemmatization didn't produce anything, use the original form\n",
    "    if len(lemma) == 0:  \n",
    "        subqueries.append(tokens[i].text)\n",
    "    elif len(lemma) == 1:\n",
    "        subqueries.append(f\"<{lemma[0]}>\")\n",
    "    else:\n",
    "        subqueries.append(f'''({' OR '.join([f\"<{alt}>\" for alt in lemma])})''')\n",
    "\n",
    "# Join all subqueries into a single adjacency query\n",
    "adjacency_lemmas = f'''\"{' THEN '.join(subqueries)}\"'''\n",
    "pprint(adjacency_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be more inclusive -- and to take account of that intervening *-que* in Lucretius -- we should probably do away with the strict sequential requirement and try instead using a proximity query. In this case, any text will match provided only that it contains the matching query terms, irrespective of their ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "'(<gelidus> OR <gelida>) AND <pruina>'",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "proximity_lemmas = f'''{' AND '.join(subqueries)}'''\n",
    "pprint(proximity_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[",
      "'Virgil'",
      ",\n ",
      "'Georgics'",
      ",\n ",
      "'poem: 2, line: 263'",
      ",\n ",
      "'<pre>ante supinatas aquiloni ostendere glaebas,</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<pre>quam laetum infodias vitis genus. Optima putri</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<match>arva solo: id venti curant <em>gelidaeque</em> '",
      "\n ",
      "'<em>pruinae</em></match>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>et labefacta movens robustus iugera fossor.</post>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>Ac si quos haud ulla viros vigilantia fugit,</post>'",
      "]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Execute the query against the given collection of texts.\n",
    "searcher = Searcher(Collection(corpus.works))\n",
    "search = searcher.search(proximity_lemmas)  \n",
    "\n",
    "# Display the query if any matches\n",
    "if search.count != (0, 0, 0):  # matches, docs, corpora\n",
    "    for result in json.loads(search.to_json())['results']:\n",
    "        pprint([result['author'],\n",
    "               result['title'],\n",
    "               result['reference'],\n",
    "               result['text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's go one step further: finding so-called 'semantic intertexts', namely texts that do not depend on a similarity of word form, but on a similarity of meaning. In this case, we are going to abstract away from the phrase's lexical composition, with a query that will look something like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[",
      "'Virgil'",
      ",\n ",
      "'Aeneid'",
      ",\n ",
      "'book: 12, line: 905'",
      ",\n ",
      "'<pre>Sed neque currentem se nec cognoscit euntem</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<pre>tollentemve manus saxumve immane moventem;</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<match>genua labant, <em>gelidus</em> concrevit <em>frigore</em> '",
      "\n ",
      "'sanguis.</match>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>Tum lapis ipse viri, vacuum per inane volutus,</post>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>nec spatium evasit totum neque pertulit ictum.</post>'",
      "]",
      "\n",
      "[",
      "'Virgil'",
      ",\n ",
      "'Georgics'",
      ",\n ",
      "'poem: 2, line: 263'",
      ",\n ",
      "'<pre>ante supinatas aquiloni ostendere glaebas,</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<pre>quam laetum infodias vitis genus. Optima putri</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<match>arva solo: id venti curant <em>gelidaeque</em> '",
      "\n ",
      "'<em>pruinae</em></match>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>et labefacta movens robustus iugera fossor.</post>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>Ac si quos haud ulla viros vigilantia fugit,</post>'",
      "]",
      "\n",
      "[",
      "'Virgil'",
      ",\n ",
      "'Georgics'",
      ",\n ",
      "'poem: 3, line: 441-poem: 3, line: 443'",
      ",\n ",
      "'<pre>arduus ad solem et linguis micat ore trisulcis.</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<pre>Morborum quoque te causas et signa docebo.</pre>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<match>Turpis ovis temptat scabies, ubi <em>frigidus</em> imber</match>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<match>altius ad vivum persedit et horrida cano</match>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<match>bruma <em>gelu,</em> vel cum tonsis inlotus adhaesit</match>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>sudor et hirsuti secuerunt corpora vepres.</post>\\n'",
      "\n ",
      "'\\n'",
      "\n ",
      "'<post>Dulcibus idcirco fluviis pecus omne magistri</post>'",
      "]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "proximity_glosses = f\"[en?icy] AND [en?frost]\"\n",
    "search = searcher.search(proximity_glosses)  \n",
    "\n",
    "# Display the query if any matches\n",
    "if search.count != (0, 0, 0):  # matches, docs, corpora\n",
    "    for result in json.loads(search.to_json())['results']:\n",
    "        pprint([result['author'],\n",
    "               result['title'],\n",
    "               result['reference'],\n",
    "               result['text']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
